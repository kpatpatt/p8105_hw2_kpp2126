---
title: "p8105_hw2_kpp2126"
author: "Kevin P. Patterson"
date: "2022-09-26"
output: github_document
---

```{r setup}
library(tidyverse)
library(dplyr)
```

## Problem 1

*Read and clean the data; 
*retain line, station_name, station latitude / longitude, routes served (route1:route11), entry, vending, entrance_type, and ADA compliance (ada). 
*Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or recode function may be useful).
```{r clean data}
transit_df =
  read.csv(
    "../../datascience/p8105_hw2_kpp2126/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(
    line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>%
  mutate(
    entry = ifelse(entry == "YES", TRUE, FALSE))

#Tidying transit data frame
transit_df_tidy = transit_df %>%
  mutate_at(c('route8', 'route9', 'route10', 'route11'), as.character)

transit_df_tidy = 
  pivot_longer(
    transit_df_tidy,
    route1:route11,
    names_to = "route",
    values_to = "train")
```

*Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. 
*Are these data tidy?

The resulting dataset has `r dim(transit_df)` observations and column variables respectively. Among the `r ncol(transit_df)` columns,  there are a mixture of numeric, logical, and character vectors in the dataframe. Despite there being `r nrow(transit_df)` observations, these do not represent the true distinct stations because there are duplicates. This is due to the dataset being in wide format, made to accommodate for columns that were in the larger dataset. Thus, the current dataframe is not tidy and I run an example of tidying the dataframe to a longer format, making the `route1:route11` columns into a single variable and its values to another variable called `train`. The dimensions of the tidied dataframe are `r dim(transit_df_tidy)` observations and columns variables respectively, reflecting the longer formatted dataframe.

*How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway; 125st Lenox); the distinct function may be useful here.
There are `465` distinct stations that are identified both by name and by line.

```{r distinct stations}
transit_df %>%
  select(station_name, line) %>%
  distinct

transit_df %>% 
  group_by(station_name) %>% 
  distinct(line)
```

*How many stations are ADA compliant?
There are `84` distinct stations, identified both by name and by line, that are ADA compliant.
```{r ada compliance}
transit_df %>%
  filter(ada == TRUE) %>%
  select(station_name, line) %>%
  distinct
```

*What proportion of station entrances / exits without vending allow entrance?
The proportion of station entrances/exits without vending that allow entrance is `r mean(transit_df[transit_df$vending == 'NO', 'entry'])`.
```{r proportion}
transit_df %>%
  filter(vending == "NO") %>%
  pull(entry) %>%
  mean
```

*Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

There are `60` distinct stations that serve the A train, and of these stations there are `17` stations are ADA compliant.
```{r reformat}
transit_df_tidy %>%
  filter(train == "A") %>%
  select(station_name, line) %>%
  distinct

transit_df_tidy %>%
  filter(train == "A", ada == TRUE) %>%
  select(station_name, line) %>%
  distinct
```

## Problem 2

Read and clean the Mr. Trash Wheel sheet:

*specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel

*use reasonable variable names
*omit rows that do not include dumpster-specific data
*round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)
*Use a similar process to import, clean, and organize the data for Professor Trash Wheel, and combine this with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to both datasets before combining.
(1)specify sheet ;(2)omit non-data entires;(3)use arguments in read_excel

```{r load clean data}
trashwheel_df =
  readxl::read_excel(
    "../../datascience/p8105_hw2_kpp2126/Trash Wheel Collection Data.xlsx",
    sheet = "Mr. Trash Wheel",
    skip = 1,
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(sports_balls = round(sports_balls),
         sports_balls = as.integer(sports_balls),
         homes_powered = as.integer(homes_powered)) %>% #made this the same as professor_df to keep sameness before binding
  add_column(sheet_type = "mister")

professortrashwheel_df =
  readxl::read_excel(
    "../../datascience/p8105_hw2_kpp2126/Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel",
    skip = 1,
    range = cell_cols("A:M")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(homes_powered = round(homes_powered),
         homes_powered = as.integer(homes_powered),
         year = as.character(year)) %>% #does this need to be the same as trashwheel_df?
  add_column(sheet_type = "professor",
             sports_balls = as.integer(NA))

#janitor::compare_df_cols(trashwheel_df, professortrashwheel_df)

combinedtrash_df = 
  bind_rows(trashwheel_df, professortrashwheel_df)
```

*Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables.

The `combinedtrash_df` has `r nrow(combinedtrash_df)` observations and `r ncol(combinedtrash_df)` variables. Of these variables,

* For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of sports balls collected by Mr. Trash Wheel in 2020?
```{r trash analysis}
#baseR calculations
sum(professortrashwheel_df$weight_tons, na.rm =T)
aggregate(combinedtrash_df$weight_tons, list(combinedtrash_df$sheet_type), FUN=sum) 
sum(trashwheel_df$sports_balls, year=2020, na.rm=T)
aggregate(combinedtrash_df, 
          list(type = sheet_type,
               year = year == "2020"),
          FUN=sum) 

#tidyverse calculations
combinedtrash_df %>%
  group_by(sheet_type) %>%
  summarise(sum = sum(weight_tons))

combinedtrash_df %>%
  group_by(sheet_type) %>%
  filter(year == "2020") %>%
  summarise(sum = sum(sports_balls))
```
## Problem 3

This problem uses the FiveThirtyEight data; these data were gathered to create the interactive graphic on this page. In particular, we’ll use the data in pols-month.csv, unemployment.csv, and snp.csv. 

*Our goal is to merge these into a single data frame using year and month as keys across datasets.*

*First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.

Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.

Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

Join the datasets by merging snp into pols, and merging unemployment into the result.

Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

Note: we could have used a date variable as a key instead of creating year and month keys; doing so would help with some kinds of plotting, and be a more accurate representation of the data. Date formats are tricky, though. For more information check out the lubridate package in the tidyverse.

```{r load clean data}
pols_df = 
  read_csv("../../datascience/p8105_hw2_kpp2126/pols-month.csv") %>%
  separate(mon, into = c("year", "month", "day"), convert = T) %>%
  mutate(month = month.abb[month])
```


